{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b0585b-ab36-42a6-b638-513b6f5a9fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\marko\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\marko\\anaconda3\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marko\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\marko\\anaconda3\\lib\\site-packages (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "# instaliranje zahtjeva\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b07ed6-eee6-4e29-a75d-9fbec234c5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marko\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dodavanje modula\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba207da-7c90-4fb0-ad62-db356987b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiranje konstanti:\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size = 32\n",
    "channels = 3\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15e58c3-d7d7-47c9-84f0-90a28b9aba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# učitavanje skupa podataka slika\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(\"C:\\\\Users\\marko\\vectrino-klasifikacija-slika\\training\\Vectrino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9713ff1d-75d9-4419-aafb-ad670db0ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slike nisu pronađene.\n"
     ]
    }
   ],
   "source": [
    "# provjera \n",
    "import os\n",
    "if os.path.exists(data_dir):\n",
    "    print(\"Slike su uspješno preuzete.\")\n",
    "else:\n",
    "    print(\"Slike nisu pronađene.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5545db13-22f8-46c5-8ffc-6b2198096694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukupan broj fotografija:  0\n"
     ]
    }
   ],
   "source": [
    "# ukupan broj fotografija koje pripadaju i iznad i ispod mora\n",
    "image_count = len(list(data_dir.glob('*/*.JPG')))\n",
    "print(\"Ukupan broj fotografija: \", image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c7a1ba-c180-4a47-82c3-b7599ed49e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory C:\\Users\\marko\u000bectrino-klasifikacija-slika\training\\Vectrino",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_vectrino \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m      2\u001b[0m     data_dir,\n\u001b[0;32m      3\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     image_size \u001b[38;5;241m=\u001b[39m (img_height, img_width),\n\u001b[0;32m      5\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\image_dataset.py:213\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mindex_directory(\n\u001b[0;32m    214\u001b[0m     directory,\n\u001b[0;32m    215\u001b[0m     labels,\n\u001b[0;32m    216\u001b[0m     formats\u001b[38;5;241m=\u001b[39mALLOWLIST_FORMATS,\n\u001b[0;32m    217\u001b[0m     class_names\u001b[38;5;241m=\u001b[39mclass_names,\n\u001b[0;32m    218\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    219\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    220\u001b[0m     follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m    221\u001b[0m )\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:542\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    544\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    776\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    778\u001b[0m ]\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory C:\\Users\\marko\u000bectrino-klasifikacija-slika\training\\Vectrino"
     ]
    }
   ],
   "source": [
    "df_vectrino = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle=True,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf514e-682e-40e4-be1a-290fbf8c6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = df_vectrino.class_names\n",
    "print(\"Nazivi klasa su: \", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a0b89-8be0-4466-87c9-3d32b4d5b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prikaz nekoliko fotografija\n",
    "plt.figure(figsize=(10,10))\n",
    "for image_batch, label_batch in df_vectrino.take(1):\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"), aspect=\"auto\")\n",
    "        plt.title(class_names[label_batch[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b752093-9e4a-4e8b-b775-ed11a3ab4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifikacije treninga:\n",
    "# 70% skupa za trening\n",
    "# 30% preostalih se dijeli u 15% za validaciju i 15% za test\n",
    "\n",
    "train_size = 0.7\n",
    "num_train_batches = int(len(df_vectrino) * train_size)\n",
    "print(f\"Za trening se koristi {train_size:.2f} skupa podataka, što znači {num_train_batches} grupa.\")\n",
    "val_size = 0.15\n",
    "num_val_batches = int(len(df_vectrino) * val_size)\n",
    "print(f\"Za validaciju se koristi {val_size:.2f} skupa podataka, što znači {num_val_batches} grupa.\")\n",
    "train_dataset = df_vectrino.take(num_train_batches)\n",
    "to_be_split = df_vectrino.skip(num_train_batches)\n",
    "validation_dataset = to_be_split.take(int(len(to_be_split) * 0.5)-1)\n",
    "test_dataset = to_be_split.skip(int(len(to_be_split) * 0.5)-1)\n",
    "print(f\"Podjela skupa podataka: Trening: {len(train_dataset)}, Validacija: {len(validation_dataset)}, Testiranje: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ae4cb-7915-46d7-8f64-d075b6993b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcija za podjelu skupa podataka slika\n",
    "def get_dataset_splitting_tf(ds, train_split=0.7, val_split=0.15, test_split=0.15, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "\n",
    "    ds_size = len(ds)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "\n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "\n",
    "    train_ds = ds.take(train_size)\n",
    "    val_test_ds = ds.skip(train_size)\n",
    "    val_ds = val_test_ds.take(val_size)\n",
    "    test_ds = val_test_ds.skip(val_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "# Poziv funkcije za podjelu skupa podataka slika\n",
    "train_dataset, validation_dataset, test_dataset = get_dataset_splitting_tf(df_vectrino)\n",
    "print(f\"Podjela skupa podataka: Trening: {len(train_dataset)}, Validacija: {len(validation_dataset)}, Testiranje: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff458467-4450-4666-b548-4ea95c3de5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizacija za brzinu treninga - brže treniranje jer su grupe u RAM-u\n",
    "# Za skup podataka za trening koristimo memoriranje u međumemoriji\n",
    "# Jer kada treniramo svoj model, zadržavamo ga u RAM-u\n",
    "# Predpriprema za bolje performanse ako treniramo na GPU-u\n",
    "\n",
    "# Skup podataka za trening\n",
    "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Skup podataka za validaciju\n",
    "validation_dataset = validation_dataset.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Skup podataka za testiranje\n",
    "test_dataset = test_dataset.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46db1f-b835-4e7a-9b98-e9f0a8509d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primjena lanca predprocesiranja - stvaranje slojeva\n",
    "# Podrška podacima - primjenjuje filtre na slike, kontrast, transformacije -> generira nove uzorke za trening\n",
    "\n",
    "# Promjena veličine i skaliranje\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "# Proširenje podataka\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.3),\n",
    "])\n",
    "\n",
    "# Primjena lanca proširenja podataka na skup za trening\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y)\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3d4da-df86-46eb-ae0c-5f0c72050a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# izgradnja modela - Convolutional Neural Network (CNN):\n",
    "\n",
    "input_shape = (batch_size, img_height, img_width, channels)\n",
    "n_classes = 2\n",
    "\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.build(input_shape=input_shape)\n",
    "\n",
    "# sumarni prikaz modela:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989dd7a8-5e86-44d4-b81c-14181fa52566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a028b-362c-43c2-9a66-c28c33138f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=validation_dataset,\n",
    "    verbose=1,\n",
    "    epochs = epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df26b0-154f-4157-ad57-c4d499f64024",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_dataset)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979ca33-03bc-479b-858e-b3c1e316dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d33312-2a83-45df-b7fb-9e941140069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs), acc, label='Training Accuracy')\n",
    "plt.plot(range(epochs), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs), loss, label='Training Loss')\n",
    "plt.plot(range(epochs), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b8e34a-3a26-4dc5-9e16-974c8a421130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predviđanje jedne slike\n",
    "import numpy as np\n",
    "for images_batch, labels_batch in test_dataset.take(1):\n",
    "\n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "\n",
    "    print(\"Prikaz stvarne i predviđene vrijednosti na jednoj slici iz testnog skupa\")\n",
    "    plt.imshow(first_image, aspect=\"auto\")\n",
    "    print(\"Stvarna vrijednost:\",class_names[first_label])\n",
    "\n",
    "    batch_prediction = model.predict(images_batch)\n",
    "    print(\"Predviđena vrijednost:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31262f3c-64af-4fa8-a664-64a1a389591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"), aspect=\"auto\")\n",
    "\n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]]\n",
    "\n",
    "        plt.title(f\"Stvarna vrijednost: {actual_class},\\n Predviđena vrijednost: {predicted_class}.\\n Pouzdanost: {confidence}%\")\n",
    "\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c423bf-296a-4ca1-89fa-7083a0c1bd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
